{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks for MNIST \n",
    "\n",
    "* The goal is to train a neural network to generate new images, that are indistinguishable from the ones contained in the MNIST database. \n",
    "\n",
    "* The main idea is to have two separate Neural Networks, a generator and a discriminator, locked in a competition with eachother.\n",
    "\n",
    "* The generator create new images as similar as possible to the pictures in the MNIST database. The discriminator try to understand if they are original pictures or synthetic ones.\n",
    "\n",
    "\n",
    "#### imports for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras imports.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "import keras.backend.tensorflow_backend as ktf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setup tensorflow session and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session(gpu_fraction=0.45):\n",
    "    '''function to setup tensorflow session and gpu settings.\n",
    "        args: amount of gpu resource to use.\n",
    "        return: tensorflow session.\n",
    "    '''\n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "\n",
    "    if num_threads:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
    "    else:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(dropout_prob = 0.4):\n",
    "    '''Builds the discriminator network\n",
    "        args: dropout probabaility\n",
    "        return: a sequential network\n",
    "    '''\n",
    "    net = Sequential()\n",
    "    input_shape = (28, 28, 1)\n",
    "    \n",
    "    net.add(Conv2D(64, 5, strides=2, input_shape=input_shape, padding='same'))\n",
    "    net.add(LeakyReLU())\n",
    "    \n",
    "    net.add(Conv2D(128, 5, strides=2, padding='same'))\n",
    "    net.add(LeakyReLU())\n",
    "    net.add(Dropout(dropout_prob))\n",
    "    \n",
    "    net.add(Conv2D(256, 5, strides=2, padding='same'))\n",
    "    net.add(LeakyReLU())\n",
    "    net.add(Dropout(dropout_prob))\n",
    "    \n",
    "    net.add(Conv2D(512, 5, strides=1, padding='same'))\n",
    "    net.add(LeakyReLU())\n",
    "    net.add(Dropout(dropout_prob))\n",
    "    \n",
    "    net.add(Flatten())\n",
    "    net.add(Dense(1))\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(dropout_prob = 0.4):\n",
    "    '''Builds the generator network\n",
    "        args: dropout probabaility\n",
    "        return: a sequential network\n",
    "    '''\n",
    "    net = Sequential()\n",
    "    \n",
    "    net.add(Dense(7*7*256, input_dim=100))\n",
    "    net.add(BatchNormalization(momentum=0.9))\n",
    "    net.add(LeakyReLU())\n",
    "    net.add(Reshape((7,7,256)))\n",
    "    net.add(Dropout(dropout_prob))\n",
    "    \n",
    "    net.add(UpSampling2D())\n",
    "    net.add(Conv2D(128, 5, padding='same'))\n",
    "    net.add(BatchNormalization(momentum=0.9))\n",
    "    net.add(LeakyReLU())\n",
    "    \n",
    "    net.add(UpSampling2D())\n",
    "    net.add(Conv2D(64, 5, padding='same'))\n",
    "    net.add(BatchNormalization(momentum=0.9))\n",
    "    net.add(LeakyReLU())\n",
    "    \n",
    "    net.add(Conv2D(32, 5, padding='same'))\n",
    "    net.add(BatchNormalization(momentum=0.9))\n",
    "    net.add(LeakyReLU())\n",
    "    \n",
    "    net.add(Conv2D(1, 5, padding='same'))\n",
    "    net.add(Activation('sigmoid'))\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net_discriminator = discriminator()\n",
    "net_discriminator.summary()\n",
    "\n",
    "net_generator = generator()\n",
    "net_generator.summary()\n",
    "\n",
    "optimiser_discriminator = RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-10)\n",
    "\n",
    "model_discriminator = Sequential()\n",
    "model_discriminator.add(net_discriminator)\n",
    "model_discriminator.compile(loss='binary_crossentropy', optimizer=optim_discriminator, metrics=['accuracy'])\n",
    "model_discriminator.summary()\n",
    "\n",
    "\n",
    "optim_adversarial = Adam(lr=0.0004, clipvalue=1.0, decay=1e-10)\n",
    "model_adversarial = Sequential()\n",
    "model_adversarial.add(net_generator)\n",
    "\n",
    "# Disable layers in discriminator\n",
    "for layer in net_discriminator.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_adversarial.add(net_discriminator)\n",
    "model_adversarial.compile(loss='binary_crossentropy', optimizer=optim_adversarial, metrics=['accuracy'])\n",
    "\n",
    "model_adversarial.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load MNIST Data and random noise for generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape((-1,28,28,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise variables for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size  = 256\n",
    "\n",
    "vis_noise = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "\n",
    "loss_adv = []\n",
    "loss_dis = []\n",
    "acc_adv = []\n",
    "acc_dis = []\n",
    "plot_iteration = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10001):\n",
    "    \n",
    "    # Select a random set of training images from the mnist dataset\n",
    "    images_train = x_train[np.random.randint(0, x_train.shape[0], size=batch_size), :, :, :]\n",
    "    \n",
    "    # Generate a random noise vector\n",
    "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "    \n",
    "    # Use the generator to create fake images from the noise vector\n",
    "    images_fake = net_generator.predict(noise)\n",
    "    \n",
    "    # Create a dataset with fake and real images\n",
    "    x = np.concatenate((images_train, images_fake))\n",
    "    y = np.ones([2*batch_size, 1])\n",
    "    y[batch_size:, :] = 0 \n",
    "\n",
    "    # Train discriminator for one batch\n",
    "    d_stats = model_discriminator.train_on_batch(x, y)\n",
    "    \n",
    "    # Train the generator\n",
    "    # The input of th adversarial model is a list of noise vectors. The generator is 'good' if the discriminator classifies\n",
    "    # all the generated images as real. Therefore, the desired output is a list of all ones.\n",
    "    y = np.ones([batch_size, 1])\n",
    "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "    a_stats = model_adversarial.train_on_batch(noise, y)\n",
    "        \n",
    "    if i % 50 == 0:\n",
    "        plot_iteration.append(i)\n",
    "        loss_adv.append(a_stats[0])\n",
    "        loss_dis.append(d_stats[0])\n",
    "        acc_adv.append(a_stats[1])\n",
    "        acc_dis.append(d_stats[1])\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "        fig.set_size_inches(16, 8)\n",
    "\n",
    "        ax1.plot(plot_iteration, loss_adv, label=\"loss adversarial\")\n",
    "        ax1.plot(plot_iteration, loss_dis, label=\"loss discriminator\")\n",
    "        ax1.set_ylim([0,5])\n",
    "        ax1.legend()\n",
    "\n",
    "        ax2.plot(plot_iteration, acc_adv, label=\"acc adversarial\")\n",
    "        ax2.plot(plot_iteration, acc_dis, label=\"acc discriminator\")\n",
    "        ax2.legend()\n",
    "        plt.show()\n",
    "       \n",
    "    #print losses instead of plotting with:\n",
    "    #print(\"{}: [Dis. loss: {:.4f}, acc: {:.4f}] [Gen. loss: {:.4f}, acc: {:.4f}]\".format(i, d_stats[0], d_stats[1], a_stats[0], a_stats[1]))\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        # Visualize the performance of the generator by producing images from the test vector\n",
    "        images = net_generator.predict(vis_noise)\n",
    "        # Map back to original range\n",
    "        #images = (images + 1 ) * 0.5\n",
    "        plt.figure(figsize=(10,10))\n",
    "        \n",
    "        for im in range(images.shape[0]):\n",
    "            plt.subplot(4, 4, im+1)\n",
    "            image = images[im, :, :, :]\n",
    "            image = np.reshape(image, [28, 28])\n",
    "            \n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(r'output/mnist-normal/{}.png'.format(i))\n",
    "        plt.close('all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test network perfromance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    noise = np.zeros([1,100]) - 1 + (i * 0.2)\n",
    "    images = net_generator.predict(noise)\n",
    "    \n",
    "    image = images[0, :, :, :]\n",
    "    image = np.reshape(image, [28, 28])\n",
    "          \n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
